{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3, HW1 :\n",
    "## Submitted by: Sayan Chakraborty, EE18MTECH11030"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import python_speech_features as speech\n",
    "import scipy.io.wavfile as wav\n",
    "import os\n",
    "import glob\n",
    "from scipy.stats import multivariate_normal as mult_gauss\n",
    "from sklearn.cluster import KMeans\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Hidden Markov Model is implemented as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM_EM(object):\n",
    "    def __init__(self, X, K, tol, data_name):\n",
    "        self.X = X                                      # X_data has dimension in the rows and observations in the coloumns\n",
    "        self.K = K                                      # Model size\n",
    "        self.N, self.d = self.X.shape                   # find the shape of the data\n",
    "        self.alpha = np.zeros((self.N,self.K))          # initialize all alpha as zero\n",
    "        self.beta = np.zeros((self.N,self.K))           # initialize all beta as zero\n",
    "        self.gamma = np.zeros((self.N,self.K))          # initialize all gamma as zero\n",
    "        self.zeta = np.zeros([self.N,self.K,self.K])\n",
    "        self.data_name = data_name\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=self.K, random_state=1).fit(self.X)\n",
    "        lables = kmeans.labels_\n",
    "        unique, counts = np.unique(lables, return_counts=True)\n",
    "\n",
    "        self.pi = np.array(counts)/self.N                 # initialize the pi\n",
    "        self.mu = np.array(kmeans.cluster_centers_).T   # initialize the means\n",
    "        self.sigma =  np.array([np.eye(self.d)]*self.K)   # initialize the covariances\n",
    "        self.A = self.normalize(np.random.rand(self.K,self.K))  # initialize transition probabilities               \n",
    "        self.tol = tol\n",
    "        \n",
    "    ## E-step \n",
    "    def get_alpha(self):\n",
    "        \n",
    "        dum = 0\n",
    "        for n in range(self.N):\n",
    "            if n == 0:\n",
    "                for k in range(self.K):\n",
    "                    self.alpha[n,k] = self.pi[k]*mult_gauss.pdf(self.X[0,:], self.mu[:,k], self.sigma[k,:,:])\n",
    "            else:\n",
    "                for k in range(self.K):\n",
    "                    self.alpha[n,k] = mult_gauss.pdf(self.X[n,:], self.mu[:,k], self.sigma[k,:,:])*\\\n",
    "                    np.dot(self.alpha[n-1,:],self.A[k,:])     \n",
    "        return self.alpha\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_beta(self):\n",
    "        \n",
    "        dum_sum = 0\n",
    "        for n in range(self.N, -1, -1):\n",
    "            if n == self.N:\n",
    "                    self.beta[n-1,:] = np.ones(self.K)\n",
    "            else:\n",
    "                for k in range(self.K):\n",
    "                    for i in range(self.K):\n",
    "                        dum_sum += self.beta[n,i]*self.A[i,k]*mult_gauss.pdf(self.X[n,:], self.mu[:,i], self.sigma[i,:,:])\n",
    "                    self.beta[n,k] = dum_sum       \n",
    "        return self.beta\n",
    "        \n",
    "    def get_gamma(self):\n",
    "        self.alpha = self.get_alpha()\n",
    "        self.beta = self.get_beta()\n",
    "        self.gamma = self.alpha*self.beta\n",
    "        return self.gamma\n",
    "    \n",
    "    def get_zeta(self):\n",
    "        self.alpha = self.get_alpha()\n",
    "        self.beta = self.get_beta()\n",
    "        for n in range(1,self.N):\n",
    "            for j in range(self.K):\n",
    "                for k in range(self.K):\n",
    "#                     print(n,j,k)\n",
    "                    self.zeta[n,j,k] = self.alpha[n-1,j]*mult_gauss.pdf(self.X[n,:], self.mu[:,k], self.sigma[k,:,:])*self.A[j,k]*self.beta[n,k]\n",
    "        return self.zeta\n",
    "    \n",
    "    \n",
    "    ## M-step\n",
    "    def M_step(self):\n",
    "        self.gamma = self.get_gamma()\n",
    "        self.zeta = self.get_zeta()\n",
    "        N_k = np.sum(self.gamma, axis = 0)\n",
    "        self.pi = self.gamma[0,:]/np.sum(self.gamma[0,:])    \n",
    "\n",
    "        self.mu = np.dot(self.gamma.T, self.X)\n",
    "        self.mu = self.mu.T/N_k\n",
    "        \n",
    "        dum_sum = 0\n",
    "        X_Data = self.X.T\n",
    "        for k in range(self.K):                    # compute sigma\n",
    "            for n in range(self.N):\n",
    "                dum_sum += np.reshape((X_Data[:,n]-self.mu[:,k]), (self.d,1))*np.reshape((X_Data[:,n]-self.mu[:,k]), (self.d,1)).T\n",
    "            self.sigma[k,:,:] = dum_sum\n",
    "\n",
    "        \n",
    "        for j in range(self.K):\n",
    "            for k in range(self.K):\n",
    "                num = np.sum(self.zeta[:,j,k])\n",
    "                den = np.sum(np.sum(self.zeta[:,j,:], axis = 0))\n",
    "                self.A[j,k] = num/den\n",
    "        \n",
    "        return self.pi, self.mu, self.sigma, self.A\n",
    "        \n",
    "\n",
    "    def normalize(self, x):\n",
    "        X = np.reshape(x, [x.shape[0],1,x.shape[1]])\n",
    "        X = X/np.reshape(np.sum(X, axis=2),[x.shape[0],1,1])\n",
    "        X = np.reshape(X,[x.shape[0],x.shape[1]])\n",
    "        return X\n",
    "    \n",
    "    def hmm_em(self):\n",
    "        a = 0\n",
    "        b = 0\n",
    "        c = 0\n",
    "        d = 0\n",
    "        error = 100\n",
    "        print('Training HMM for the data: '+self.data_name, '\\n')\n",
    "        while(error>self.tol):\n",
    "            self.pi, self.mu, self.sigma, self.A = self.M_step()\n",
    "            error = LA.norm(self.pi-a)+LA.norm(self.mu-b)+LA.norm(self.sigma-c)+LA.norm(self.A-d)\n",
    "            a = self.pi\n",
    "            b = self.mu\n",
    "            c = self.sigma\n",
    "            d = self.A \n",
    "        print('Training completed for the data: '+self.data_name, '\\n')\n",
    "        print('--------------------------------- \\n')\n",
    "        return self.pi, self.mu, self.sigma, self.A\n",
    "\n",
    "\n",
    "def scale(X, x_min, x_max):\n",
    "    nom = (X-X.min(axis=0))*(x_max-x_min)\n",
    "    denom = X.max(axis=0) - X.min(axis=0)\n",
    "    denom[denom==0] = 1\n",
    "    return x_min + nom/denom "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training:\n",
    "### Two phones are chosen for this implementation: 1) bha 2)bhe\n",
    "### The HMM implemented above is trained on the these data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training HMM for the data: training_bha.wav \n",
      "\n",
      "Training completed for the data: training_bha.wav \n",
      "\n",
      "--------------------------------- \n",
      "\n",
      "Training HMM for the data: training_bhe.wav \n",
      "\n",
      "Training completed for the data: training_bhe.wav \n",
      "\n",
      "--------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "K = 3\n",
    "tol = 0.0001\n",
    "\n",
    "############## Training for bha #############################\n",
    "data_name = \"training_bha.wav\"\n",
    "(rate,sig) = wav.read(data_name)\n",
    "X_Data = speech.mfcc(sig,rate)\n",
    "\n",
    "X_Data = scale(X_Data, -1, 1)\n",
    "obj = HMM_EM(X_Data, K, tol, data_name)\n",
    "pi_bha, mu_bha, sigma_bha, A_bha = obj.hmm_em()\n",
    "#############################################################\n",
    "\n",
    "############## Training for bhe #############################\n",
    "\n",
    "data_name = \"training_bhe.wav\"\n",
    "(rate,sig) = wav.read(data_name)\n",
    "X_Data = speech.mfcc(sig,rate)\n",
    "\n",
    "X_Data = scale(X_Data, -1, 1)\n",
    "obj = HMM_EM(X_Data, K, tol, data_name)\n",
    "pi_bhe, mu_bhe, sigma_bhe, A_bhe = obj.hmm_em()\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier:\n",
    "### The classifier is implemenetd below.\n",
    "### First the HMM parameters for a training set (with no overlapping with testinf set) is obtained using the HMM implemenetd aobe.\n",
    "### After obtaining the parametrs for a training set, we compare the obtained parameters with the previously trained parametrs for datasets bha and bhe.\n",
    "### The training set belongs to the dataset which yields the lest error.\n",
    "### Similar to the training set, two testing sets are prepared for the two chosen phones bha and bhe with no overlap with the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training HMM for the data: testing_bha.wav \n",
      "\n",
      "Training completed for the data: testing_bha.wav \n",
      "\n",
      "--------------------------------- \n",
      "\n",
      "training data belongs to dataset bha\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_test = \"testing_bha.wav\"\n",
    "# data_test = \"testing_bhe.wav\"\n",
    "(rate,sig) = wav.read(data_test)\n",
    "X_Data = speech.mfcc(sig,rate)\n",
    "X_Data = scale(X_Data, -1, 1)\n",
    "obj = HMM_EM(X_Data, K, tol, data_test)\n",
    "pi_test, mu_test, sigma_test, A_test = obj.hmm_em()\n",
    "error_bha = LA.norm(pi_test-pi_bha)+LA.norm(mu_test-mu_bha)+LA.norm(sigma_test-sigma_bha)+LA.norm(A_test-A_bha)\n",
    "error_bhe = LA.norm(pi_test-pi_bhe)+LA.norm(mu_test-mu_bhe)+LA.norm(sigma_test-sigma_bhe)+LA.norm(A_test-A_bhe)\n",
    "if error_bha<error_bhe:\n",
    "    print(\"training data belongs to dataset bha\\n\")\n",
    "else:\n",
    "    print(\"training data belongs to dataset bhe\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
